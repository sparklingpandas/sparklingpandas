language: python
sudo: false
python:
  - "2.7"
install:
  # build our scala code
  - ./sbt/sbt assembly
  # We do this conditionally because it saves us some downloading if the
  # version is the same.
  - if [[ "$TRAVIS_PYTHON_VERSION" == "2.7" ]]; then
      wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh;
    else
      wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  # Useful for debugging any issues with conda
  - conda info -a
  - deps='pip numpy pandas requests nose numpydoc sphinx pep8 pylint scipy openpyxl unittest2 py4j'
  # Replace dep1 dep2 ... with your dependencies
  - conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION $deps
  - source activate test-environment
  - python setup.py install  - export PATH=$HOME/py/bin:$PATH
script:
  # Download spark 1.4.1
  - "wget http://d3kbcqa49mib13.cloudfront.net/spark-1.4.1-bin-hadoop2.4.tgz"
  - "tar -xf spark-1.4.1-bin-hadoop2.4.tgz"
  # Run the tests
  - "export SPARK_HOME=./spark-1.4.1-bin-hadoop2.4/"
  - "nosetests --logging-level=INFO --detailed-errors --verbosity=2 --with-coverage --cover-html-dir=./htmlcov --cover-package=sparklingpandas"
  - "pep8 --ignore=E402 sparklingpandas/"
  - "pylint -E sparklingpandas --extension-pkg-whitelist=numpy --disable=no-member"
after_success:
  - codecov
